{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ted/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "from sklearn import linear_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import seaborn\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following steps is to calculate the sentiment analysis scores of the NY Times articles we have previously scraped.\n",
    "\n",
    "In the first step, after we have read in the various CSVs for the articles, we use a function called \"tuple_generator\". The purpose of this function is to take the articles we have, and extract the month from the date category and then assign the month to each article. This will be useful because we are calculating monthly sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cache = [pd.read_csv(filename) for filename in glob.glob(\"/Users/Ted/Desktop/CS109/nytimes_data/*.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#argument: dataframe\n",
    "#The purpose of this function is to take all the articles and to assign the month to each article\n",
    "#We avoid using dictionaries because as long as this is in order of the year, it doesn't matter \n",
    "def tuple_generator(df):\n",
    "    x = df[\"date\"].str.replace(\"-\", \"/\")\n",
    "    lst = []\n",
    "    for j in xrange(len(x)):\n",
    "        spl = str(x[j]).split(\"/\")\n",
    "        if int(spl[0]) > 12:\n",
    "            lst.append(int(spl[1]))\n",
    "        else:\n",
    "            lst.append(int(spl[0]))\n",
    "    month = pd.Series(lst)\n",
    "    df[\"month\"] = month\n",
    "    df['tuple_headline'] = list(zip(df[\"headline\"], df[\"month\"]))\n",
    "    df['tuple_snippet'] = list(zip(df[\"snippet\"], df[\"month\"]))\n",
    "\n",
    "    headline_date = list(df[\"tuple_headline\"])\n",
    "    snippet_date = list(df[\"tuple_snippet\"])\n",
    "    \n",
    "    return headline_date, snippet_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our monthly_sentiment function makes a call to an external API which calculates the sentiment scores for us. The Sentiment Analysis aspect of the API requires making an HTTP POST request with form encoded data, and using the publicly available nltk-trainer to train on publicly available text datasets of movie reviews. The text classification uses a Naive Bayes Classifier and high information feature selection to build up a model, which calculates the polarity and neutrality of the text (and spits it back out as a decimal that adds to 1), and then within the polarity, it calculates the probability that a text if positive or negative (and spits it back out as a decimal that adds to 1). \n",
    "\n",
    "\n",
    "The documentation and links for the following referenced are below:\n",
    "\n",
    "text-processing (the API we used): http://text-processing.com/\n",
    "movie review data sets: http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "nltk-trainer: https://github.com/japerk/nltk-trainer, http://nltk-trainer.readthedocs.io/en/latest/train_classifier.html\n",
    "text classification using naive bayes: http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "text classification by eliminating low information features: http://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import simplejson because the errors messages are more descriptive and helpful\n",
    "import simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes the results of the tuple generator and returns\n",
    "#the positive and neutral scores for each month\n",
    "\n",
    "def monthly_sentiment(dt):\n",
    "    neu_list = []\n",
    "    pos_list = []\n",
    "    r = requests.post(\"http://text-processing.com/api/sentiment/\", data={\"text\": dt[0][0]})\n",
    "    j = simplejson.loads(r.text)\n",
    "    p = j['probability']\n",
    "    sum_neu = p['neutral']\n",
    "    sum_pos = p['pos']\n",
    "    for i in range(1, len(dt)):\n",
    "        r = requests.post(\"http://text-processing.com/api/sentiment/\", data={\"text\": dt[i][0]})\n",
    "        j = simplejson.loads(r.text)\n",
    "        p = j['probability']\n",
    "        pos = p['pos']\n",
    "        neu = p['neutral']\n",
    "        if (dt[i][1] == dt[i-1][1]):\n",
    "            sum_pos += pos\n",
    "            sum_neu += neu\n",
    "        else:\n",
    "            pos_list.append(sum_pos)\n",
    "            neu_list.append(sum_neu)\n",
    "            sum_pos = pos\n",
    "            sum_neu = neu\n",
    "    pos_list.append(sum_pos)\n",
    "    neu_list.append(sum_neu)\n",
    "    \n",
    "    return pos_list, neu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the functions ready, we run the tuple generator and monthly sentiment part on all the years. This process took a very, very long time because we were frequently rate limited/throttled by the API and had to wait 24 hours each time before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_lst = []\n",
    "neu_lst = []\n",
    "headline_lst = []\n",
    "#runs tuple generator for every year, then runs monthly sentiment analysis\n",
    "#WARNING: TAKES HOURS AND WILL TIME OUT AS THE API BLOCKS YOU\n",
    "#ONCE TIMED OUT, MUST WAIT ~24 HOURS TO TRY AGAIN\n",
    "\n",
    "for i in xrange(1982, 2017):\n",
    "    h, s = tuple_generator(cache[i - 1982])\n",
    "    headline_lst.append(h)\n",
    "    pos, neu = monthly_sentiment(h)\n",
    "    pos_lst.append(pos)\n",
    "    neu_lst.append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dictionaries to store and map to each year\n",
    "sent_pos = {}\n",
    "sent_neut = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(1982, 2017):\n",
    "    sent_pos[i] = pos_lst[i - 1982]\n",
    "    sent_neut[i] = neu_lst[i - 1982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#provides a count of how many articles there are in each month\n",
    "#for the purpose of standardizing scores if need be\n",
    "def standard (dt):\n",
    "    d = {}\n",
    "    for i in range(0, len(dt)):\n",
    "        key = int(dt[i][1])\n",
    "        if key in d:\n",
    "            d[key] += 1\n",
    "        else:\n",
    "            d[key] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# headlines: all the headlines from a year\n",
    "# pos: all pos scores per month\n",
    "# neu: all neutral scores per month\n",
    "# year: the year for which this is done for\n",
    "\n",
    "def generate_df(headlines, pos, neu, year):\n",
    "    #count number of articles per month\n",
    "    counts = standard(headlines)\n",
    "    stand_pos = []\n",
    "    stand_neu = []\n",
    "    #loop through and save the standardized values\n",
    "    for i in xrange(len(pos)):\n",
    "        scored_pos = pos[i]/(counts[i+1])\n",
    "        scored_neu = neg[i]/(counts[i+1])\n",
    "        stand_pos.append(scored_pos)\n",
    "        stand_neu.append(scored_neu)\n",
    "    df = pd.DataFrame([pos, neu, stand_pos, stand_neu]).transpose()\n",
    "    df.columns = [\"positive\", \"neutral\", \"positive_standard\", \"neutral_standard\"]\n",
    "    #write to csv\n",
    "    df.to_csv(\"sentiment_scores/SA_scores_%d.csv\" % year)\n",
    "    #return df for visual inspection\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive_standard</th>\n",
       "      <th>neutral_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.725509</td>\n",
       "      <td>61.355917</td>\n",
       "      <td>0.486724</td>\n",
       "      <td>0.639124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.735867</td>\n",
       "      <td>54.228944</td>\n",
       "      <td>0.502650</td>\n",
       "      <td>0.609314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.504184</td>\n",
       "      <td>52.014345</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.611933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.444549</td>\n",
       "      <td>44.547312</td>\n",
       "      <td>0.499172</td>\n",
       "      <td>0.664885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.650605</td>\n",
       "      <td>48.745805</td>\n",
       "      <td>0.501956</td>\n",
       "      <td>0.633062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.417927</td>\n",
       "      <td>68.434460</td>\n",
       "      <td>0.518621</td>\n",
       "      <td>0.664412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.280530</td>\n",
       "      <td>71.679104</td>\n",
       "      <td>0.507295</td>\n",
       "      <td>0.669898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.077008</td>\n",
       "      <td>66.189158</td>\n",
       "      <td>0.505828</td>\n",
       "      <td>0.668577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.327100</td>\n",
       "      <td>58.086724</td>\n",
       "      <td>0.491989</td>\n",
       "      <td>0.691509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60.521036</td>\n",
       "      <td>78.901987</td>\n",
       "      <td>0.508580</td>\n",
       "      <td>0.663042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.170347</td>\n",
       "      <td>67.596189</td>\n",
       "      <td>0.491866</td>\n",
       "      <td>0.662708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.860529</td>\n",
       "      <td>59.630999</td>\n",
       "      <td>0.498484</td>\n",
       "      <td>0.648163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     positive    neutral  positive_standard  neutral_standard\n",
       "0   46.725509  61.355917           0.486724          0.639124\n",
       "1   44.735867  54.228944           0.502650          0.609314\n",
       "2   42.504184  52.014345           0.500049          0.611933\n",
       "3   33.444549  44.547312           0.499172          0.664885\n",
       "4   38.650605  48.745805           0.501956          0.633062\n",
       "5   53.417927  68.434460           0.518621          0.664412\n",
       "6   54.280530  71.679104           0.507295          0.669898\n",
       "7   50.077008  66.189158           0.505828          0.668577\n",
       "8   41.327100  58.086724           0.491989          0.691509\n",
       "9   60.521036  78.901987           0.508580          0.663042\n",
       "10  50.170347  67.596189           0.491866          0.662708\n",
       "11  45.860529  59.630999           0.498484          0.648163"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example for 1982\n",
    "generate_df(headline_lst[0], pos_lst[0], neg_lst[0], 1982)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop through and generate CSV's for each year\n",
    "for i in xrange(1982, 2017):\n",
    "    curr = i - 1982\n",
    "    generate_df(headline_lst[curr], pos_lst[curr], neu_lst[curr], i)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
